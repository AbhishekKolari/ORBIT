{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fef7e23",
   "metadata": {
    "papermill": {
     "duration": 0.005878,
     "end_time": "2025-07-28T14:03:38.908550",
     "exception": false,
     "start_time": "2025-07-28T14:03:38.902672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VLM Benchmark for Object Property Abstraction\n",
    "\n",
    "This notebook implements a benchmark for evaluating Vision Language Models (VLMs) on object property abstraction and visual question answering (VQA) tasks. The benchmark includes three types of questions:\n",
    "\n",
    "1. Direct Recognition\n",
    "2. Property Inference\n",
    "3. Counterfactual Reasoning\n",
    "\n",
    "And three types of images:\n",
    "- REAL\n",
    "- ANIMATED\n",
    "- AI GENERATED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492240cd",
   "metadata": {
    "papermill": {
     "duration": 0.004939,
     "end_time": "2025-07-28T14:03:38.918956",
     "exception": false,
     "start_time": "2025-07-28T14:03:38.914017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "310ebe2d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-28T14:03:38.930404Z",
     "iopub.status.busy": "2025-07-28T14:03:38.929687Z",
     "iopub.status.idle": "2025-07-28T14:03:38.934069Z",
     "shell.execute_reply": "2025-07-28T14:03:38.933307Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.011242,
     "end_time": "2025-07-28T14:03:38.935250",
     "exception": false,
     "start_time": "2025-07-28T14:03:38.924008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# %pip install transformers torch Pillow tqdm bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4551413",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-07-28T14:03:38.946218Z",
     "iopub.status.busy": "2025-07-28T14:03:38.945902Z",
     "iopub.status.idle": "2025-07-28T14:03:40.684215Z",
     "shell.execute_reply": "2025-07-28T14:03:40.683255Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 1.745268,
     "end_time": "2025-07-28T14:03:40.685602",
     "exception": false,
     "start_time": "2025-07-28T14:03:38.940334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qwen-vl-utils in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (0.0.11)\r\n",
      "Requirement already satisfied: flash-attn in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (2.7.4.post1)\r\n",
      "Requirement already satisfied: av in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from qwen-vl-utils) (14.3.0)\r\n",
      "Requirement already satisfied: packaging in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from qwen-vl-utils) (25.0)\r\n",
      "Requirement already satisfied: pillow in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from qwen-vl-utils) (10.3.0)\r\n",
      "Requirement already satisfied: requests in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from qwen-vl-utils) (2.32.3)\r\n",
      "Requirement already satisfied: torch in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from flash-attn) (2.2.1)\r\n",
      "Requirement already satisfied: einops in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from flash-attn) (0.8.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->qwen-vl-utils) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->qwen-vl-utils) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->qwen-vl-utils) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from requests->qwen-vl-utils) (2025.4.26)\r\n",
      "Requirement already satisfied: filelock in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (4.13.2)\r\n",
      "Requirement already satisfied: sympy in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (8.9.2.26)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.3.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (11.0.2.54)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (10.3.2.106)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (11.4.5.107)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.0.106)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (2.19.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from torch->flash-attn) (12.1.105)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.8.93)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from jinja2->torch->flash-attn) (3.0.2)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages (from sympy->torch->flash-attn) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install qwen-vl-utils flash-attn #--no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de455c0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:03:40.698488Z",
     "iopub.status.busy": "2025-07-28T14:03:40.698034Z",
     "iopub.status.idle": "2025-07-28T14:03:46.430672Z",
     "shell.execute_reply": "2025-07-28T14:03:46.429730Z"
    },
    "papermill": {
     "duration": 5.740236,
     "end_time": "2025-07-28T14:03:46.432018",
     "exception": false,
     "start_time": "2025-07-28T14:03:40.691782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/scratch/ave303/anaconda3/envs/op_bench/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import gc\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import time\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7baf9ef",
   "metadata": {
    "papermill": {
     "duration": 0.005387,
     "end_time": "2025-07-28T14:03:46.443737",
     "exception": false,
     "start_time": "2025-07-28T14:03:46.438350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Benchmark Tester Class\n",
    "\n",
    "This class handles the evaluation of models against our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c1615b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:03:46.456565Z",
     "iopub.status.busy": "2025-07-28T14:03:46.456165Z",
     "iopub.status.idle": "2025-07-28T14:03:46.467224Z",
     "shell.execute_reply": "2025-07-28T14:03:46.466480Z"
    },
    "papermill": {
     "duration": 0.019196,
     "end_time": "2025-07-28T14:03:46.468371",
     "exception": false,
     "start_time": "2025-07-28T14:03:46.449175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class BenchmarkTester:\n",
    "#     def __init__(self, benchmark_path=\"/var/scratch/ave303/OP_bench/benchmark.json\", data_dir=\"/var/scratch/ave303/OP_bench/\"):\n",
    "#         self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#         with open(benchmark_path, 'r') as f:\n",
    "#             self.benchmark = json.load(f)\n",
    "#         self.data_dir = data_dir\n",
    "    \n",
    "#     def format_question(self, question, model_name):\n",
    "#         \"\"\"Format a question for the model.\"\"\"\n",
    "\n",
    "#         if model_name==\"blip2\":\n",
    "#             return f\"Question: {question['question']} Answer:\"\n",
    "#         else:\n",
    "#             return f\"Question: {question['question']} Answer with a number and list of objects. Answer:\"\n",
    "\n",
    "#     def clean_answer(self, answer):\n",
    "#         \"\"\"Clean the model output to extract just the number.\"\"\"\n",
    "#         # Remove any text that's not a number\n",
    "#         # import re\n",
    "#         # numbers = re.findall(r'\\d+', answer)\n",
    "#         # if numbers:\n",
    "#         #     return numbers[0]  # Return the first number found\n",
    "#         # return answer\n",
    "#         \"\"\"Extract number and reasoning from the model's answer.\"\"\"\n",
    "#         # Try to extract number and reasoning using regex\n",
    "#         import re\n",
    "#         pattern = r'(\\d+)\\s*\\[(.*?)\\]'\n",
    "#         match = re.search(pattern, answer)\n",
    "        \n",
    "#         if match:\n",
    "#             number = match.group(1)\n",
    "#             objects = [obj.strip() for obj in match.group(2).split(',')]\n",
    "#             return {\n",
    "#                 \"count\": number,\n",
    "#                 \"reasoning\": objects\n",
    "#             }\n",
    "#         else:\n",
    "#             # Fallback if format isn't matched\n",
    "#             numbers = re.findall(r'\\d+', answer)\n",
    "#             return {\n",
    "#                 \"count\": numbers[0] if numbers else \"0\",\n",
    "#                 \"reasoning\": []\n",
    "#             }\n",
    "\n",
    "#     def model_generation(self, model_name, model, inputs, processor):\n",
    "#         \"\"\"Generate answer and decode.\"\"\"\n",
    "#         outputs = None  # Initialize outputs to None\n",
    "        \n",
    "#         if model_name==\"smolVLM2\":\n",
    "#             outputs = model.generate(**inputs, do_sample=False, max_new_tokens=64)\n",
    "#             answer = processor.batch_decode(\n",
    "#                 outputs,\n",
    "#                 skip_special_tokens=True,\n",
    "#             )[0]\n",
    "#         elif model_name==\"Qwen2.5-VL\":\n",
    "#             outputs = model.generate(**inputs, max_new_tokens=50)\n",
    "#             outputs = [\n",
    "#                 out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, outputs)\n",
    "#             ]\n",
    "#             answer = processor.batch_decode(\n",
    "#                 outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "#             )[0]\n",
    "#         else:\n",
    "#             print(f\"Warning: Unknown model name '{model_name}' in model_generation.\")\n",
    "#             answer = \"\"  # Return an empty string\n",
    "\n",
    "#         return answer, outputs\n",
    "    \n",
    "#     def evaluate_model(self, model_name, model, processor, save_path, start_idx=0, batch_size=5):\n",
    "#         results = []\n",
    "#         print(f\"\\nEvaluating {model_name}...\")\n",
    "#         print(f\"Using device: {self.device}\")\n",
    "        \n",
    "#         # Force garbage collection before starting\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "\n",
    "#         try:\n",
    "#             images = self.benchmark['benchmark']['images'][start_idx:start_idx + batch_size]\n",
    "#             total_images = len(images)\n",
    "            \n",
    "#             for idx, image_data in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "#                 try:\n",
    "#                     print(f\"\\nProcessing image {idx+1}/{total_images}: {image_data['image_id']}\")\n",
    "#                     image_path = Path(self.data_dir)/image_data['path']\n",
    "#                     if not image_path.exists():\n",
    "#                         print(f\"Warning: Image not found at {image_path}\")\n",
    "#                         continue\n",
    "                    \n",
    "#                     # Load and preprocess image\n",
    "#                     image = Image.open(image_path).convert(\"RGB\")\n",
    "#                     image_results = []  # Store results for current image\n",
    "                    \n",
    "#                     for question in image_data['questions']:\n",
    "#                         try:\n",
    "#                             # prompt = self.format_question(question, model_name)\n",
    "#                             print(f\"Question: {question['question']}\")\n",
    "\n",
    "#                             messages = [\n",
    "#                                 {\n",
    "#                                     \"role\": \"user\",\n",
    "#                                     \"content\": [\n",
    "#                                         {\"type\": \"image\", \"image\": image},\n",
    "#                                         # {\"type\": \"text\", \"text\": f\"{question['question']} Answer format: total number(numerical) objects(within square brackets)\"},\n",
    "#                                         # {\"type\": \"text\", \"text\": f\"{question['question']} Provide just the total count and the list of objects in the given format \\n Format: number [objects]\"},\n",
    "#                                         # {\"type\": \"text\", \"text\": f\"{question['question']} Answer Format: number [objects]\"},\n",
    "#                                         {\"type\": \"text\", \"text\": f\"{question[\"question\"]} Your response MUST be in the following format and nothing else:\\n <NUMBER> [<OBJECT1>, <OBJECT2>, <OBJECT3>, ...]\"}\n",
    "#                                     ]\n",
    "#                                 },\n",
    "#                             ]\n",
    "                            \n",
    "#                             # Clear cache before processing each question\n",
    "#                             torch.cuda.empty_cache()\n",
    "                            \n",
    "#                             # Process image and text\n",
    "#                             # inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(self.device)\n",
    "#                             if model_name==\"smolVLM2\":\n",
    "#                                 inputs = processor.apply_chat_template(\n",
    "#                                     messages,\n",
    "#                                     add_generation_prompt=True,\n",
    "#                                     tokenize=True,\n",
    "#                                     return_dict=True,\n",
    "#                                     return_tensors=\"pt\",\n",
    "#                                 ).to(model.device, dtype=torch.float16)\n",
    "#                             else:\n",
    "                                \n",
    "#                                 text = processor.apply_chat_template(\n",
    "#                                     messages, tokenize=False, add_generation_prompt=True\n",
    "#                                 )\n",
    "#                                 # image_inputs, video_inputs = process_vision_info(messages)\n",
    "#                                 inputs = processor(\n",
    "#                                     text=text,\n",
    "#                                     images=image,\n",
    "#                                     videos=None,\n",
    "#                                     padding=True,\n",
    "#                                     return_tensors=\"pt\",\n",
    "#                                 ).to(\"cuda\")\n",
    "                            \n",
    "#                             # Generate answer with better settings\n",
    "#                             with torch.no_grad():\n",
    "#                                 answer, outputs = self.model_generation(model_name, model, inputs, processor)    #call for model.generate\n",
    "        \n",
    "#                             cleaned_answer = self.clean_answer(answer)\n",
    "                            \n",
    "#                             image_results.append({\n",
    "#                                 \"image_id\": image_data[\"image_id\"],\n",
    "#                                 \"image_type\": image_data[\"image_type\"],\n",
    "#                                 \"question_id\": question[\"id\"],\n",
    "#                                 \"question\": question[\"question\"],\n",
    "#                                 \"ground_truth\": question[\"answer\"],\n",
    "#                                 \"model_answer\": cleaned_answer[\"count\"],\n",
    "#                                 \"model_reasoning\": cleaned_answer[\"reasoning\"],\n",
    "#                                 \"raw_answer\": answer,  # Keep raw answer for debugging\n",
    "#                                 \"property_category\": question[\"property_category\"]\n",
    "#                             })\n",
    "                            \n",
    "#                             # Clear memory\n",
    "#                             del outputs, inputs\n",
    "#                             torch.cuda.empty_cache()\n",
    "                            \n",
    "#                         except Exception as e:\n",
    "#                             print(f\"Error processing question: {str(e)}\")\n",
    "#                             continue\n",
    "                    \n",
    "#                     # Add results from this image\n",
    "#                     results.extend(image_results)\n",
    "                    \n",
    "#                     # Save intermediate results only every 2 images or if it's the last image\n",
    "#                     if (idx + 1) % 2 == 0 or idx == total_images - 1:\n",
    "#                         with open(f\"{save_path}_checkpoint.json\", 'w') as f:\n",
    "#                             json.dump(results, f, indent=4)\n",
    "                            \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing image {image_data['image_id']}: {str(e)}\")\n",
    "#                     continue\n",
    "            \n",
    "#             # Save final results\n",
    "#             if results:\n",
    "#                 with open(save_path, 'w') as f:\n",
    "#                     json.dump(results, f, indent=4)\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"An error occurred during evaluation: {str(e)}\")\n",
    "#             if results:\n",
    "#                 with open(f\"{save_path}_error_state.json\", 'w') as f:\n",
    "#                     json.dump(results, f, indent=4)\n",
    "        \n",
    "#         return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67377d93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:03:46.480782Z",
     "iopub.status.busy": "2025-07-28T14:03:46.480543Z",
     "iopub.status.idle": "2025-07-28T14:03:46.514918Z",
     "shell.execute_reply": "2025-07-28T14:03:46.514115Z"
    },
    "papermill": {
     "duration": 0.042134,
     "end_time": "2025-07-28T14:03:46.516138",
     "exception": false,
     "start_time": "2025-07-28T14:03:46.474004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BenchmarkTester:\n",
    "    def __init__(self, benchmark_path=\"/var/scratch/ave303/OP_bench/benchmark.json\", data_dir=\"/var/scratch/ave303/OP_bench/\"):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        with open(benchmark_path, 'r') as f:\n",
    "            self.benchmark = json.load(f)\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "    def clean_answer(self, answer):\n",
    "        \"\"\"Extract number and reasoning from the model's answer.\"\"\"\n",
    "        # Try to extract number and reasoning using regex\n",
    "        import re\n",
    "        pattern = r'(\\d+)\\s*\\[(.*?)\\]'\n",
    "        match = re.search(pattern, answer)\n",
    "        \n",
    "        if match:\n",
    "            number = match.group(1)\n",
    "            objects = [obj.strip() for obj in match.group(2).split(',')]\n",
    "            return {\n",
    "                \"count\": number,\n",
    "                \"reasoning\": objects\n",
    "            }\n",
    "        else:\n",
    "            # Fallback if format isn't matched\n",
    "            numbers = re.findall(r'\\d+', answer)\n",
    "            return {\n",
    "                \"count\": numbers[0] if numbers else \"0\",\n",
    "                \"reasoning\": []\n",
    "            }\n",
    "\n",
    "    def model_generation(self, model_name, model, inputs, processor):\n",
    "        \"\"\"Generate answer and decode with greedy decoding.\"\"\"\n",
    "        outputs = None  # Initialize outputs to None\n",
    "        \n",
    "        if model_name == \"Qwen2.5-VL\":\n",
    "            # Explicit greedy decoding parameters\n",
    "            outputs = model.generate(\n",
    "                **inputs, \n",
    "                max_new_tokens=200,\n",
    "                do_sample=False,          # Disable sampling for greedy decoding\n",
    "                temperature=None,         # Not used in greedy decoding\n",
    "                top_p=None,              # Not used in greedy decoding  \n",
    "                top_k=None,              # Not used in greedy decoding\n",
    "                num_beams=1,             # Single beam for greedy decoding\n",
    "                early_stopping=False,    # Let it generate until max_tokens or EOS\n",
    "                pad_token_id=processor.tokenizer.pad_token_id,\n",
    "                eos_token_id=processor.tokenizer.eos_token_id\n",
    "            )\n",
    "            outputs = [\n",
    "                out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, outputs)\n",
    "            ]\n",
    "            answer = processor.batch_decode(\n",
    "                outputs, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "            )[0]\n",
    "        else:\n",
    "            print(f\"Warning: Unknown model name '{model_name}' in model_generation.\")\n",
    "            answer = \"\"  # Return an empty string\n",
    "\n",
    "        return answer, outputs\n",
    "    \n",
    "    def evaluate_model(self, model_name, model, processor, save_path, start_idx=0, batch_size=5):\n",
    "        results = []\n",
    "        \n",
    "        # Initialize tracking variables\n",
    "        successful_images = []\n",
    "        failed_images = []\n",
    "        total_questions_processed = 0\n",
    "        total_questions_failed = 0\n",
    "        \n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Force garbage collection before starting\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        try:\n",
    "            images = self.benchmark['benchmark']['images'][start_idx:start_idx + batch_size]\n",
    "            total_images = len(images)\n",
    "            \n",
    "            for idx, image_data in enumerate(tqdm(images, desc=\"Processing images\")):\n",
    "                image_start_time = time.time()\n",
    "                current_image_questions_failed = 0\n",
    "                current_image_questions_total = 0\n",
    "                \n",
    "                try:\n",
    "                    image_path = Path(self.data_dir)/image_data['path']\n",
    "                    if not image_path.exists():\n",
    "                        failed_images.append({\n",
    "                            'image_id': image_data['image_id'],\n",
    "                            'image_type': image_data.get('image_type', 'unknown'),\n",
    "                            'error_type': 'file_not_found',\n",
    "                            'error_message': f'Image not found at {image_path}'\n",
    "                        })\n",
    "                        continue\n",
    "                    \n",
    "                    # Load and preprocess image\n",
    "                    image = Image.open(image_path).convert(\"RGB\")\n",
    "                    image_results = []  # Store results for current image\n",
    "                    \n",
    "                    for question_idx, question in enumerate(image_data['questions']):\n",
    "                        current_image_questions_total += 1\n",
    "                        total_questions_processed += 1\n",
    "                        \n",
    "                        try:\n",
    "                            messages = [\n",
    "                                {\n",
    "                                    \"role\": \"user\",\n",
    "                                    \"content\": [\n",
    "                                        {\"type\": \"image\", \"image\": image},\n",
    "                                        {\"type\": \"text\", \"text\": f\"{question['question']} Your response MUST be in the following format and nothing else:\\n <NUMBER> [<OBJECT1>, <OBJECT2>, <OBJECT3>, ...]\"}\n",
    "                                    ]\n",
    "                                },\n",
    "                            ]\n",
    "                            \n",
    "                            # Clear cache before processing each question\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                            # Process image and text for Qwen2.5-VL\n",
    "                            text = processor.apply_chat_template(\n",
    "                                messages, tokenize=False, add_generation_prompt=True\n",
    "                            )\n",
    "                            inputs = processor(\n",
    "                                text=text,\n",
    "                                images=image,\n",
    "                                videos=None,\n",
    "                                padding=True,\n",
    "                                return_tensors=\"pt\",\n",
    "                            ).to(\"cuda\")\n",
    "                            \n",
    "                            # Generate answer with greedy decoding\n",
    "                            with torch.no_grad():\n",
    "                                answer, outputs = self.model_generation(model_name, model, inputs, processor)\n",
    "        \n",
    "                            cleaned_answer = self.clean_answer(answer)\n",
    "                            \n",
    "                            image_results.append({\n",
    "                                \"image_id\": image_data[\"image_id\"],\n",
    "                                \"image_type\": image_data.get(\"image_type\", \"unknown\"),\n",
    "                                \"question_id\": question[\"id\"],\n",
    "                                \"question\": question[\"question\"],\n",
    "                                \"ground_truth\": question[\"answer\"],\n",
    "                                \"model_answer\": cleaned_answer[\"count\"],\n",
    "                                \"model_reasoning\": cleaned_answer[\"reasoning\"],\n",
    "                                \"raw_answer\": answer,  # Keep raw answer for debugging\n",
    "                                \"property_category\": question[\"property_category\"]\n",
    "                            })\n",
    "                            \n",
    "                            # Clear memory\n",
    "                            del outputs, inputs\n",
    "                            torch.cuda.empty_cache()\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            current_image_questions_failed += 1\n",
    "                            total_questions_failed += 1\n",
    "                            continue\n",
    "                    \n",
    "                    # Add results from this image\n",
    "                    results.extend(image_results)\n",
    "                    \n",
    "                    # Calculate success rate for this image\n",
    "                    questions_succeeded = current_image_questions_total - current_image_questions_failed\n",
    "                    \n",
    "                    if current_image_questions_failed == 0:\n",
    "                        # All questions succeeded\n",
    "                        successful_images.append({\n",
    "                            'image_id': image_data['image_id'],\n",
    "                            'image_type': image_data.get('image_type', 'unknown'),\n",
    "                            'questions_total': current_image_questions_total,\n",
    "                            'questions_succeeded': questions_succeeded,\n",
    "                            'processing_time': time.time() - image_start_time\n",
    "                        })\n",
    "                    else:\n",
    "                        # Some questions failed\n",
    "                        image_success_rate = (questions_succeeded / current_image_questions_total * 100) if current_image_questions_total > 0 else 0\n",
    "                        failed_images.append({\n",
    "                            'image_id': image_data['image_id'],\n",
    "                            'image_type': image_data.get('image_type', 'unknown'),\n",
    "                            'error_type': 'partial_failure',\n",
    "                            'questions_total': current_image_questions_total,\n",
    "                            'questions_failed': current_image_questions_failed,\n",
    "                            'questions_succeeded': questions_succeeded,\n",
    "                            'success_rate': f\"{image_success_rate:.1f}%\"\n",
    "                        })\n",
    "                    \n",
    "                    # Save intermediate results only every 2 images or if it's the last image\n",
    "                    if (idx + 1) % 2 == 0 or idx == total_images - 1:\n",
    "                        checkpoint_path = f\"{save_path}_checkpoint.json\"\n",
    "                        with open(checkpoint_path, 'w') as f:\n",
    "                            json.dump(results, f, indent=4)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    failed_images.append({\n",
    "                        'image_id': image_data['image_id'],\n",
    "                        'image_type': image_data.get('image_type', 'unknown'),\n",
    "                        'error_type': 'complete_failure',\n",
    "                        'error_message': str(e)\n",
    "                    })\n",
    "                    continue\n",
    "            \n",
    "            # Save final results\n",
    "            if results:\n",
    "                with open(save_path, 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if results:\n",
    "                error_save_path = f\"{save_path}_error_state.json\"\n",
    "                with open(error_save_path, 'w') as f:\n",
    "                    json.dump(results, f, indent=4)\n",
    "        \n",
    "        # Print comprehensive summary\n",
    "        self._print_evaluation_summary(\n",
    "            model_name, total_images, successful_images, failed_images, \n",
    "            total_questions_processed, total_questions_failed, len(results)\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _print_evaluation_summary(self, model_name, total_images, successful_images, \n",
    "                                failed_images, total_questions_processed, total_questions_failed, total_results):\n",
    "        \"\"\"Print a comprehensive evaluation summary.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"EVALUATION SUMMARY FOR {model_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Image-level statistics\n",
    "        num_successful = len(successful_images)\n",
    "        num_failed = len(failed_images)\n",
    "        \n",
    "        print(f\"ðŸ“Š IMAGE PROCESSING SUMMARY:\")\n",
    "        print(f\"   Total images attempted: {total_images}\")\n",
    "        print(f\"   Successfully processed: {num_successful} ({num_successful/total_images*100:.1f}%)\")\n",
    "        print(f\"   Failed images: {num_failed} ({num_failed/total_images*100:.1f}%)\")\n",
    "        \n",
    "        # Question-level statistics\n",
    "        questions_succeeded = total_questions_processed - total_questions_failed\n",
    "        print(f\"\\nðŸ“ QUESTION PROCESSING SUMMARY:\")\n",
    "        print(f\"   Total questions attempted: {total_questions_processed}\")\n",
    "        print(f\"   Successfully processed: {questions_succeeded} ({questions_succeeded/total_questions_processed*100:.1f}%)\")\n",
    "        print(f\"   Failed questions: {total_questions_failed} ({total_questions_failed/total_questions_processed*100:.1f}%)\")\n",
    "        print(f\"   Results saved: {total_results}\")\n",
    "        \n",
    "        # Successful images details\n",
    "        if successful_images:\n",
    "            print(f\"\\nâœ… SUCCESSFUL IMAGES ({len(successful_images)}):\")\n",
    "            for img in successful_images:\n",
    "                print(f\"   â€¢ {img['image_id']} (Type: {img['image_type']}, \"\n",
    "                      f\"Questions: {img['questions_succeeded']}/{img['questions_total']}, \"\n",
    "                      f\"Time: {img['processing_time']:.1f}s)\")\n",
    "        \n",
    "        # Failed images details\n",
    "        if failed_images:\n",
    "            print(f\"\\nâŒ FAILED/PROBLEMATIC IMAGES ({len(failed_images)}):\")\n",
    "            for img in failed_images:\n",
    "                if img['error_type'] == 'complete_failure':\n",
    "                    print(f\"   â€¢ {img['image_id']} (Type: {img['image_type']}) - \"\n",
    "                          f\"COMPLETE FAILURE: {img.get('error_message', 'Unknown error')}\")\n",
    "                elif img['error_type'] == 'partial_failure':\n",
    "                    print(f\"   â€¢ {img['image_id']} (Type: {img['image_type']}) - \"\n",
    "                          f\"PARTIAL: {img['questions_failed']}/{img['questions_total']} failed \"\n",
    "                          f\"({img['success_rate']} success)\")\n",
    "                elif img['error_type'] == 'file_not_found':\n",
    "                    print(f\"   â€¢ {img['image_id']} (Type: {img['image_type']}) - \"\n",
    "                          f\"FILE NOT FOUND: {img['error_message']}\")\n",
    "        \n",
    "        # Group failed images by type\n",
    "        if failed_images:\n",
    "            print(f\"\\nðŸ“ˆ FAILURE ANALYSIS BY IMAGE TYPE:\")\n",
    "            from collections import defaultdict\n",
    "            failures_by_type = defaultdict(list)\n",
    "            for img in failed_images:\n",
    "                failures_by_type[img['image_type']].append(img)\n",
    "            \n",
    "            for img_type, failures in failures_by_type.items():\n",
    "                print(f\"   â€¢ {img_type}: {len(failures)} failed images\")\n",
    "                for failure in failures:\n",
    "                    print(f\"     - {failure['image_id']} ({failure['error_type']})\")\n",
    "        \n",
    "        print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74831b4",
   "metadata": {
    "papermill": {
     "duration": 0.005386,
     "end_time": "2025-07-28T14:03:46.527093",
     "exception": false,
     "start_time": "2025-07-28T14:03:46.521707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test SmolVLM Model\n",
    "\n",
    "Let's evaluate the SmolVLM2-2.2B-Instruct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7328a56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:03:46.539018Z",
     "iopub.status.busy": "2025-07-28T14:03:46.538778Z",
     "iopub.status.idle": "2025-07-28T14:03:46.543194Z",
     "shell.execute_reply": "2025-07-28T14:03:46.542441Z"
    },
    "papermill": {
     "duration": 0.011674,
     "end_time": "2025-07-28T14:03:46.544321",
     "exception": false,
     "start_time": "2025-07-28T14:03:46.532647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def test_smolVLM2():\n",
    "#     from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "\n",
    "#     print(\"Loading smolVLM model...\")\n",
    "    \n",
    "#     model = AutoModelForImageTextToText.from_pretrained(\n",
    "#         \"HuggingFaceTB/SmolVLM2-2.2B-Instruct\",\n",
    "#         torch_dtype=torch.float16,\n",
    "#         attn_implementation=\"flash_attention_2\",\n",
    "#         low_cpu_mem_usage=True,\n",
    "#         trust_remote_code=True\n",
    "#     ).to(\"cuda\")\n",
    "\n",
    "#     processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM2-2.2B-Instruct\")\n",
    "\n",
    "#     ## A bit slow without the flash_attention2 requires ampere gpu's. Better performance in some cases\n",
    "\n",
    "#     # Optional: Enable memory efficient attention\n",
    "#     if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "#         model.config.use_memory_efficient_attention = True\n",
    "\n",
    "#     tester = BenchmarkTester()\n",
    "#     smolVLM_results = tester.evaluate_model(\n",
    "#         \"smolVLM2\",\n",
    "#         model, \n",
    "#         processor, \n",
    "#         \"smolVLM2_results_1.json\", \n",
    "#         batch_size=25\n",
    "#     )\n",
    "\n",
    "#     # Clean up\n",
    "#     del model, processor\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e0ecbe",
   "metadata": {
    "papermill": {
     "duration": 0.005322,
     "end_time": "2025-07-28T14:03:46.555302",
     "exception": false,
     "start_time": "2025-07-28T14:03:46.549980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Qwen2.5-VL\n",
    "\n",
    "Lets evaluate the Qwen2.5-VL-7B-Instruct model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35cb639d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:03:46.567333Z",
     "iopub.status.busy": "2025-07-28T14:03:46.567014Z",
     "iopub.status.idle": "2025-07-28T14:03:46.572763Z",
     "shell.execute_reply": "2025-07-28T14:03:46.572116Z"
    },
    "papermill": {
     "duration": 0.013072,
     "end_time": "2025-07-28T14:03:46.573924",
     "exception": false,
     "start_time": "2025-07-28T14:03:46.560852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_Qwen2_5VL():\n",
    "    from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "    \n",
    "    # default: Load the model on the available device(s)\n",
    "    # model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    #     \"Qwen/Qwen2.5-VL-3B-Instruct\", \n",
    "    #     load_in_8bit=True, # throws error when .to() is added\n",
    "    #     torch_dtype=torch.bfloat16, \n",
    "    #     device_map=\"auto\",\n",
    "    #     # attn_implementation=\"flash_attention_2\",\n",
    "    #     low_cpu_mem_usage=True\n",
    "    # )\n",
    "    \n",
    "    # We recommend enabling flash_attention_2 for better acceleration and memory saving, especially in multi-image and video scenarios.\n",
    "    model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "        \"/var/scratch/ave303/models/qwen2-5-vl-32b\",\n",
    "        torch_dtype=torch.float16,\n",
    "        # attn_implementation=\"flash_attention_2\",\n",
    "        device_map=\"auto\",\n",
    "        low_cpu_mem_usage=True,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # default processer\n",
    "    processor = AutoProcessor.from_pretrained(\"/var/scratch/ave303/models/qwen2-5-vl-32b\")\n",
    "\n",
    "    ### Qwen2.5-VL-7B-Instruct --> goes out of CUDA memory\n",
    "    ### Qwen2.5-VL-3B-Instruct --> can handle only 2 images before going out of memory but decent performance\n",
    "\n",
    "    # Optional: Enable memory efficient attention\n",
    "    if hasattr(model.config, 'use_memory_efficient_attention'):\n",
    "        model.config.use_memory_efficient_attention = True\n",
    "\n",
    "    tester = BenchmarkTester()\n",
    "    Qwen2_5VL_results = tester.evaluate_model(\n",
    "        \"Qwen2.5-VL\",\n",
    "        model, \n",
    "        processor, \n",
    "        \"Qwen2.5-VL_32b_results.json\",\n",
    "        # start_idx=2,\n",
    "        batch_size=360\n",
    "    )\n",
    "\n",
    "    # Clean up\n",
    "    del model, processor\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce02ce",
   "metadata": {
    "papermill": {
     "duration": 0.005366,
     "end_time": "2025-07-28T14:03:46.584903",
     "exception": false,
     "start_time": "2025-07-28T14:03:46.579537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Run Evaluation\n",
    "\n",
    "Now we can run our evaluation. Let's start with the SmolVLM2 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ffdade4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:03:46.596891Z",
     "iopub.status.busy": "2025-07-28T14:03:46.596656Z",
     "iopub.status.idle": "2025-07-28T14:03:46.600160Z",
     "shell.execute_reply": "2025-07-28T14:03:46.599430Z"
    },
    "papermill": {
     "duration": 0.010811,
     "end_time": "2025-07-28T14:03:46.601346",
     "exception": false,
     "start_time": "2025-07-28T14:03:46.590535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_smolVLM2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba954a45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-28T14:03:46.613441Z",
     "iopub.status.busy": "2025-07-28T14:03:46.613130Z",
     "iopub.status.idle": "2025-07-28T20:21:14.585021Z",
     "shell.execute_reply": "2025-07-28T20:21:14.584142Z"
    },
    "papermill": {
     "duration": 22647.979257,
     "end_time": "2025-07-28T20:21:14.586371",
     "exception": false,
     "start_time": "2025-07-28T14:03:46.607114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:   3%|â–Ž         | 1/30 [00:01<00:56,  1.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:   7%|â–‹         | 2/30 [00:04<01:03,  2.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  10%|â–ˆ         | 3/30 [00:07<01:05,  2.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  13%|â–ˆâ–Ž        | 4/30 [00:09<01:03,  2.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  17%|â–ˆâ–‹        | 5/30 [00:12<01:01,  2.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 6/30 [00:14<01:01,  2.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [00:17<01:00,  2.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:20<00:57,  2.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [00:22<00:55,  2.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:25<00:52,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:27<00:49,  2.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:30<00:47,  2.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [00:33<00:45,  2.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [00:36<00:44,  2.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [00:39<00:42,  2.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:42<00:39,  2.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [00:44<00:35,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [00:47<00:34,  2.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:50<00:31,  2.83s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [00:53<00:27,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:55<00:23,  2.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:58<00:20,  2.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [01:00<00:17,  2.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [01:03<00:15,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [01:05<00:13,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [01:08<00:10,  2.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [01:11<00:08,  2.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [01:14<00:05,  2.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [01:17<00:02,  2.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [01:19<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [01:19<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Qwen2.5-VL...\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   0%|          | 0/360 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   0%|          | 1/360 [01:06<6:39:28, 66.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   1%|          | 2/360 [02:29<7:34:45, 76.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   1%|          | 3/360 [03:41<7:20:40, 74.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   1%|          | 4/360 [05:05<7:43:54, 78.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   1%|â–         | 5/360 [06:31<7:58:51, 80.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   2%|â–         | 6/360 [08:23<8:59:13, 91.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   2%|â–         | 7/360 [09:07<7:27:13, 76.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   2%|â–         | 8/360 [09:39<6:03:30, 61.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   2%|â–Ž         | 9/360 [10:57<6:32:25, 67.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   3%|â–Ž         | 10/360 [12:48<7:49:54, 80.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   3%|â–Ž         | 11/360 [13:38<6:53:54, 71.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   3%|â–Ž         | 12/360 [15:28<8:01:43, 83.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   4%|â–Ž         | 13/360 [16:32<7:26:03, 77.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   4%|â–         | 14/360 [17:01<6:01:21, 62.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   4%|â–         | 15/360 [18:29<6:45:11, 70.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   4%|â–         | 16/360 [20:03<7:24:53, 77.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   5%|â–         | 17/360 [21:00<6:47:36, 71.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   5%|â–Œ         | 18/360 [22:06<6:37:05, 69.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   5%|â–Œ         | 19/360 [23:33<7:05:06, 74.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   6%|â–Œ         | 20/360 [24:31<6:35:20, 69.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   6%|â–Œ         | 21/360 [26:01<7:09:28, 76.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   6%|â–Œ         | 22/360 [26:06<5:07:23, 54.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   6%|â–‹         | 23/360 [26:11<3:42:56, 39.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   7%|â–‹         | 24/360 [27:28<4:45:28, 50.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   7%|â–‹         | 25/360 [28:23<4:51:30, 52.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   7%|â–‹         | 26/360 [29:56<5:58:51, 64.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   8%|â–Š         | 27/360 [30:45<5:31:31, 59.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   8%|â–Š         | 28/360 [31:51<5:40:29, 61.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   8%|â–Š         | 29/360 [33:23<6:29:34, 70.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   8%|â–Š         | 30/360 [34:28<6:20:36, 69.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   9%|â–Š         | 31/360 [35:52<6:43:12, 73.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   9%|â–‰         | 32/360 [37:11<6:51:01, 75.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   9%|â–‰         | 33/360 [38:04<6:13:43, 68.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:   9%|â–‰         | 34/360 [39:08<6:03:57, 66.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  10%|â–‰         | 35/360 [41:55<8:45:24, 97.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  10%|â–ˆ         | 36/360 [44:10<9:46:12, 108.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  10%|â–ˆ         | 37/360 [45:31<8:59:41, 100.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  11%|â–ˆ         | 38/360 [46:30<7:51:20, 87.83s/it] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  11%|â–ˆ         | 39/360 [47:34<7:12:22, 80.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  11%|â–ˆ         | 40/360 [49:00<7:18:45, 82.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  11%|â–ˆâ–        | 41/360 [49:44<6:16:16, 70.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  12%|â–ˆâ–        | 42/360 [50:26<5:29:50, 62.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  12%|â–ˆâ–        | 43/360 [51:22<5:18:53, 60.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  12%|â–ˆâ–        | 44/360 [52:35<5:37:53, 64.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  12%|â–ˆâ–Ž        | 45/360 [54:34<7:02:32, 80.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  13%|â–ˆâ–Ž        | 46/360 [56:40<8:13:10, 94.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  13%|â–ˆâ–Ž        | 47/360 [57:37<7:13:34, 83.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  13%|â–ˆâ–Ž        | 48/360 [58:25<6:16:33, 72.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  14%|â–ˆâ–Ž        | 49/360 [59:32<6:07:33, 70.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  14%|â–ˆâ–        | 50/360 [1:00:43<6:06:52, 71.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  14%|â–ˆâ–        | 51/360 [1:02:37<7:11:49, 83.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  14%|â–ˆâ–        | 52/360 [1:03:30<6:22:10, 74.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  15%|â–ˆâ–        | 53/360 [1:04:38<6:11:38, 72.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  15%|â–ˆâ–Œ        | 54/360 [1:04:42<4:25:03, 51.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  15%|â–ˆâ–Œ        | 55/360 [1:05:35<4:26:02, 52.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  16%|â–ˆâ–Œ        | 56/360 [1:05:39<3:11:54, 37.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  16%|â–ˆâ–Œ        | 57/360 [1:07:25<4:54:21, 58.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  16%|â–ˆâ–Œ        | 58/360 [1:08:26<4:56:37, 58.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  16%|â–ˆâ–‹        | 59/360 [1:09:22<4:51:33, 58.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  17%|â–ˆâ–‹        | 60/360 [1:11:05<5:57:41, 71.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  17%|â–ˆâ–‹        | 61/360 [1:12:21<6:03:46, 73.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  17%|â–ˆâ–‹        | 62/360 [1:13:07<5:22:03, 64.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  18%|â–ˆâ–Š        | 63/360 [1:14:35<5:55:20, 71.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  18%|â–ˆâ–Š        | 64/360 [1:14:50<4:29:38, 54.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  18%|â–ˆâ–Š        | 65/360 [1:15:54<4:43:07, 57.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  18%|â–ˆâ–Š        | 66/360 [1:16:42<4:27:40, 54.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  19%|â–ˆâ–Š        | 67/360 [1:17:59<4:59:19, 61.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  19%|â–ˆâ–‰        | 68/360 [1:19:17<5:23:18, 66.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  19%|â–ˆâ–‰        | 69/360 [1:20:58<6:13:00, 76.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  19%|â–ˆâ–‰        | 70/360 [1:21:59<5:47:51, 71.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  20%|â–ˆâ–‰        | 71/360 [1:22:13<4:23:44, 54.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  20%|â–ˆâ–ˆ        | 72/360 [1:23:14<4:31:00, 56.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  20%|â–ˆâ–ˆ        | 73/360 [1:23:54<4:07:15, 51.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  21%|â–ˆâ–ˆ        | 74/360 [1:25:04<4:31:38, 56.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  21%|â–ˆâ–ˆ        | 75/360 [1:25:08<3:14:58, 41.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  21%|â–ˆâ–ˆ        | 76/360 [1:26:10<3:44:35, 47.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  21%|â–ˆâ–ˆâ–       | 77/360 [1:26:49<3:31:37, 44.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  22%|â–ˆâ–ˆâ–       | 78/360 [1:28:33<4:54:01, 62.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  22%|â–ˆâ–ˆâ–       | 79/360 [1:30:27<6:05:51, 78.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  22%|â–ˆâ–ˆâ–       | 80/360 [1:31:25<5:36:32, 72.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  22%|â–ˆâ–ˆâ–Ž       | 81/360 [1:32:07<4:53:34, 63.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  23%|â–ˆâ–ˆâ–Ž       | 82/360 [1:33:14<4:57:27, 64.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  23%|â–ˆâ–ˆâ–Ž       | 83/360 [1:34:12<4:48:12, 62.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  23%|â–ˆâ–ˆâ–Ž       | 84/360 [1:34:15<3:25:23, 44.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  24%|â–ˆâ–ˆâ–Ž       | 85/360 [1:34:33<2:46:43, 36.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  24%|â–ˆâ–ˆâ–       | 86/360 [1:35:19<3:00:13, 39.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  24%|â–ˆâ–ˆâ–       | 87/360 [1:36:41<3:57:42, 52.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  24%|â–ˆâ–ˆâ–       | 88/360 [1:37:55<4:25:43, 58.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  25%|â–ˆâ–ˆâ–       | 89/360 [1:38:09<3:25:05, 45.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  25%|â–ˆâ–ˆâ–Œ       | 90/360 [1:38:48<3:14:51, 43.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  25%|â–ˆâ–ˆâ–Œ       | 91/360 [1:40:34<4:39:07, 62.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  26%|â–ˆâ–ˆâ–Œ       | 92/360 [1:40:38<3:19:51, 44.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  26%|â–ˆâ–ˆâ–Œ       | 93/360 [1:41:37<3:37:31, 48.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  26%|â–ˆâ–ˆâ–Œ       | 94/360 [1:42:41<3:56:52, 53.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  26%|â–ˆâ–ˆâ–‹       | 95/360 [1:43:36<3:57:58, 53.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  27%|â–ˆâ–ˆâ–‹       | 96/360 [1:45:02<4:40:22, 63.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  27%|â–ˆâ–ˆâ–‹       | 97/360 [1:45:17<3:34:45, 48.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  27%|â–ˆâ–ˆâ–‹       | 98/360 [1:46:32<4:07:40, 56.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  28%|â–ˆâ–ˆâ–Š       | 99/360 [1:46:35<2:56:45, 40.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  28%|â–ˆâ–ˆâ–Š       | 100/360 [1:48:11<4:08:55, 57.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  28%|â–ˆâ–ˆâ–Š       | 101/360 [1:50:02<5:16:50, 73.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  28%|â–ˆâ–ˆâ–Š       | 102/360 [1:51:19<5:20:46, 74.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  29%|â–ˆâ–ˆâ–Š       | 103/360 [1:52:45<5:33:40, 77.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  29%|â–ˆâ–ˆâ–‰       | 104/360 [1:54:00<5:28:26, 76.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  29%|â–ˆâ–ˆâ–‰       | 105/360 [1:55:27<5:40:39, 80.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  29%|â–ˆâ–ˆâ–‰       | 106/360 [1:57:07<6:04:32, 86.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  30%|â–ˆâ–ˆâ–‰       | 107/360 [1:58:31<6:00:12, 85.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  30%|â–ˆâ–ˆâ–ˆ       | 108/360 [1:58:46<4:29:34, 64.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  30%|â–ˆâ–ˆâ–ˆ       | 109/360 [1:58:48<3:10:49, 45.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  31%|â–ˆâ–ˆâ–ˆ       | 110/360 [1:58:51<2:15:57, 32.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  31%|â–ˆâ–ˆâ–ˆ       | 111/360 [1:58:53<1:38:25, 23.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  31%|â–ˆâ–ˆâ–ˆ       | 112/360 [2:00:40<3:20:56, 48.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  31%|â–ˆâ–ˆâ–ˆâ–      | 113/360 [2:02:53<5:04:22, 73.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  32%|â–ˆâ–ˆâ–ˆâ–      | 114/360 [2:04:53<5:59:14, 87.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  32%|â–ˆâ–ˆâ–ˆâ–      | 115/360 [2:06:07<5:41:56, 83.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  32%|â–ˆâ–ˆâ–ˆâ–      | 116/360 [2:06:22<4:16:16, 63.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 117/360 [2:07:31<4:21:58, 64.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 118/360 [2:09:31<5:27:39, 81.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 119/360 [2:10:46<5:19:41, 79.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 120/360 [2:12:44<6:04:15, 91.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 121/360 [2:13:52<5:35:04, 84.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  34%|â–ˆâ–ˆâ–ˆâ–      | 122/360 [2:14:54<5:07:55, 77.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  34%|â–ˆâ–ˆâ–ˆâ–      | 123/360 [2:15:37<4:25:21, 67.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  34%|â–ˆâ–ˆâ–ˆâ–      | 124/360 [2:16:52<4:33:16, 69.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  35%|â–ˆâ–ˆâ–ˆâ–      | 125/360 [2:18:02<4:32:04, 69.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 126/360 [2:18:57<4:14:30, 65.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 127/360 [2:19:36<3:43:08, 57.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 128/360 [2:20:32<3:40:15, 56.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 129/360 [2:22:03<4:18:04, 67.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 130/360 [2:22:07<3:04:40, 48.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 131/360 [2:23:44<4:00:34, 63.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 132/360 [2:26:12<5:35:59, 88.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 133/360 [2:26:51<4:38:00, 73.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 134/360 [2:28:05<4:37:34, 73.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 135/360 [2:28:07<3:16:17, 52.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 136/360 [2:28:10<2:19:41, 37.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 137/360 [2:29:26<3:01:41, 48.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 138/360 [2:30:27<3:15:06, 52.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 139/360 [2:32:19<4:19:04, 70.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 140/360 [2:33:28<4:16:48, 70.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 141/360 [2:33:32<3:03:10, 50.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 142/360 [2:35:06<3:49:41, 63.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 143/360 [2:35:10<2:44:29, 45.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 144/360 [2:36:03<2:51:34, 47.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 145/360 [2:37:00<3:00:50, 50.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 146/360 [2:38:24<3:36:04, 60.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 147/360 [2:39:43<3:54:29, 66.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 148/360 [2:41:37<4:44:52, 80.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 149/360 [2:42:39<4:24:08, 75.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/360 [2:43:23<3:49:30, 65.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 151/360 [2:44:43<4:04:04, 70.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 152/360 [2:45:13<3:20:51, 57.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 153/360 [2:45:48<2:56:24, 51.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 154/360 [2:46:29<2:44:48, 48.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 155/360 [2:47:40<3:08:05, 55.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 156/360 [2:48:43<3:14:38, 57.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 157/360 [2:49:50<3:24:14, 60.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 158/360 [2:51:08<3:40:43, 65.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 159/360 [2:52:21<3:46:57, 67.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 160/360 [2:53:12<3:28:59, 62.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 161/360 [2:53:16<2:29:20, 45.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 162/360 [2:53:18<1:46:39, 32.32s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 163/360 [2:53:22<1:18:06, 23.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 164/360 [2:53:27<59:33, 18.23s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 165/360 [2:53:31<45:20, 13.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 166/360 [2:53:36<35:39, 11.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 167/360 [2:53:38<27:28,  8.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 168/360 [2:53:41<21:29,  6.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 169/360 [2:53:44<17:42,  5.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 170/360 [2:55:19<1:42:51, 32.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 171/360 [2:55:23<1:15:23, 23.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 172/360 [2:55:27<56:18, 17.97s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 173/360 [2:55:31<42:52, 13.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 174/360 [2:56:35<1:28:59, 28.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 175/360 [2:57:12<1:36:28, 31.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 176/360 [2:57:44<1:36:36, 31.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 177/360 [2:58:16<1:36:35, 31.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 178/360 [2:58:20<1:10:46, 23.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 179/360 [2:58:24<52:43, 17.48s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 180/360 [2:59:06<1:15:12, 25.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 181/360 [2:59:40<1:22:28, 27.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 182/360 [3:01:17<2:23:28, 48.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 183/360 [3:03:05<3:15:40, 66.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 184/360 [3:03:49<2:55:10, 59.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 185/360 [3:04:48<2:53:43, 59.56s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 186/360 [3:05:32<2:39:01, 54.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 187/360 [3:06:23<2:34:43, 53.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 188/360 [3:07:30<2:44:50, 57.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 189/360 [3:08:45<2:58:57, 62.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 190/360 [3:09:27<2:40:07, 56.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 191/360 [3:10:12<2:29:35, 53.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 192/360 [3:11:35<2:53:33, 61.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 193/360 [3:12:48<3:01:57, 65.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 194/360 [3:13:38<2:48:06, 60.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 195/360 [3:14:35<2:44:12, 59.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 196/360 [3:16:06<3:08:36, 69.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 197/360 [3:17:44<3:31:36, 77.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 198/360 [3:18:54<3:23:18, 75.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 199/360 [3:19:49<3:05:41, 69.20s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 200/360 [3:21:35<3:34:23, 80.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 201/360 [3:22:54<3:31:41, 79.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 202/360 [3:23:49<3:10:41, 72.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 203/360 [3:24:40<2:52:52, 66.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 204/360 [3:24:44<2:03:32, 47.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 205/360 [3:25:20<1:53:55, 44.10s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 206/360 [3:26:17<2:03:06, 47.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 207/360 [3:27:13<2:08:24, 50.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 208/360 [3:28:05<2:08:52, 50.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 209/360 [3:28:55<2:07:10, 50.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 210/360 [3:29:27<1:52:36, 45.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 211/360 [3:30:27<2:02:23, 49.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 212/360 [3:31:38<2:18:10, 56.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 213/360 [3:32:57<2:34:04, 62.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 214/360 [3:33:53<2:27:40, 60.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 215/360 [3:34:32<2:11:14, 54.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 216/360 [3:35:27<2:10:19, 54.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 217/360 [3:36:13<2:03:38, 51.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 218/360 [3:36:57<1:57:32, 49.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 219/360 [3:38:03<2:08:14, 54.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 220/360 [3:38:50<2:01:40, 52.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 221/360 [3:39:26<1:49:38, 47.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 222/360 [3:40:47<2:12:29, 57.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 223/360 [3:42:21<2:36:25, 68.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 224/360 [3:43:13<2:23:55, 63.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 225/360 [3:44:11<2:18:43, 61.65s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 226/360 [3:45:49<2:42:06, 72.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 227/360 [3:46:31<2:20:56, 63.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 228/360 [3:46:58<1:55:18, 52.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 229/360 [3:47:59<2:00:20, 55.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 230/360 [3:48:03<1:26:03, 39.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 231/360 [3:48:07<1:02:19, 28.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 232/360 [3:48:11<46:20, 21.73s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 233/360 [3:48:15<34:41, 16.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 234/360 [3:48:18<25:38, 12.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 235/360 [3:48:22<20:16,  9.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 236/360 [3:48:26<16:37,  8.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 237/360 [3:48:30<13:54,  6.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 238/360 [3:48:34<12:03,  5.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 239/360 [3:48:38<10:44,  5.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 240/360 [3:48:41<09:46,  4.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 241/360 [3:49:41<42:14, 21.30s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 242/360 [3:50:40<1:04:06, 32.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 243/360 [3:51:50<1:25:19, 43.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 244/360 [3:53:13<1:47:38, 55.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 245/360 [3:54:31<1:59:12, 62.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 246/360 [3:55:43<2:03:46, 65.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 247/360 [3:56:39<1:57:40, 62.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 248/360 [3:58:33<2:25:20, 77.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 249/360 [3:59:29<2:11:51, 71.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 250/360 [4:00:55<2:19:08, 75.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 251/360 [4:02:36<2:31:27, 83.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 252/360 [4:03:21<2:08:59, 71.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 253/360 [4:04:17<1:59:32, 67.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 254/360 [4:05:05<1:48:24, 61.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 255/360 [4:06:35<2:02:26, 69.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 256/360 [4:07:47<2:02:21, 70.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 257/360 [4:08:39<1:51:42, 65.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 258/360 [4:10:45<2:21:47, 83.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 259/360 [4:12:04<2:18:06, 82.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 260/360 [4:13:05<2:06:01, 75.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 261/360 [4:13:46<1:47:36, 65.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 262/360 [4:14:59<1:50:30, 67.66s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 263/360 [4:16:09<1:50:36, 68.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 264/360 [4:17:23<1:51:51, 69.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 265/360 [4:18:13<1:41:08, 63.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 266/360 [4:19:21<1:42:26, 65.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 267/360 [4:20:20<1:38:01, 63.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 268/360 [4:21:08<1:29:58, 58.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 269/360 [4:21:44<1:18:42, 51.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 270/360 [4:22:47<1:22:51, 55.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 271/360 [4:23:59<1:29:25, 60.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 272/360 [4:24:51<1:24:51, 57.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 273/360 [4:25:57<1:27:31, 60.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 274/360 [4:27:36<1:42:55, 71.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 275/360 [4:28:48<1:42:02, 72.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 276/360 [4:30:02<1:41:24, 72.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 277/360 [4:30:46<1:28:37, 64.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 278/360 [4:31:45<1:25:28, 62.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 279/360 [4:32:38<1:20:33, 59.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 280/360 [4:33:41<1:20:38, 60.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 281/360 [4:34:43<1:20:28, 61.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 282/360 [4:35:57<1:24:15, 64.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 283/360 [4:37:08<1:25:30, 66.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 284/360 [4:38:27<1:29:25, 70.60s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 285/360 [4:39:23<1:22:31, 66.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 286/360 [4:41:16<1:38:50, 80.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 287/360 [4:42:18<1:31:04, 74.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 288/360 [4:43:44<1:33:51, 78.21s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 289/360 [4:45:04<1:33:03, 78.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 290/360 [4:46:51<1:41:50, 87.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 291/360 [4:48:33<1:45:08, 91.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 292/360 [4:50:42<1:56:38, 102.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 293/360 [4:52:22<1:53:47, 101.90s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 294/360 [4:54:45<2:05:53, 114.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 295/360 [4:56:14<1:55:34, 106.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 296/360 [4:57:07<1:36:30, 90.47s/it] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 297/360 [4:58:10<1:26:33, 82.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 298/360 [5:00:26<1:41:47, 98.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 299/360 [5:01:33<1:30:27, 88.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 300/360 [5:02:54<1:26:31, 86.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 301/360 [5:04:34<1:29:13, 90.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 302/360 [5:06:51<1:40:59, 104.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 303/360 [5:08:23<1:35:43, 100.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 304/360 [5:09:32<1:25:06, 91.19s/it] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 305/360 [5:10:37<1:16:29, 83.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 306/360 [5:12:01<1:15:10, 83.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 307/360 [5:13:19<1:12:22, 81.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 308/360 [5:14:32<1:08:34, 79.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 309/360 [5:16:14<1:13:04, 85.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 310/360 [5:18:21<1:21:51, 98.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 311/360 [5:19:02<1:06:10, 81.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 312/360 [5:19:48<56:30, 70.63s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 313/360 [5:21:32<1:03:09, 80.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 314/360 [5:22:20<54:18, 70.84s/it]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 315/360 [5:23:04<47:11, 62.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 316/360 [5:23:43<40:54, 55.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 317/360 [5:25:38<52:30, 73.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 318/360 [5:27:00<53:08, 75.92s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 319/360 [5:28:07<50:05, 73.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 320/360 [5:29:50<54:51, 82.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 321/360 [5:30:54<49:59, 76.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 322/360 [5:31:55<45:34, 71.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 323/360 [5:33:10<44:52, 72.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 324/360 [5:34:41<46:58, 78.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 325/360 [5:35:17<38:21, 65.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 326/360 [5:36:24<37:30, 66.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 327/360 [5:37:33<36:52, 67.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 328/360 [5:38:25<33:16, 62.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 329/360 [5:39:11<29:40, 57.45s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 330/360 [5:40:29<31:52, 63.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 331/360 [5:41:40<31:47, 65.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 332/360 [5:42:48<30:59, 66.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 333/360 [5:43:44<28:28, 63.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 334/360 [5:45:07<30:03, 69.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 335/360 [5:46:38<31:36, 75.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 336/360 [5:47:45<29:17, 73.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 337/360 [5:48:55<27:39, 72.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 338/360 [5:50:07<26:29, 72.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 339/360 [5:51:37<27:05, 77.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 340/360 [5:53:02<26:33, 79.69s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 341/360 [5:54:31<26:05, 82.41s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 342/360 [5:55:35<23:04, 76.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 343/360 [5:56:27<19:42, 69.58s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 344/360 [5:57:48<19:26, 72.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 345/360 [5:58:41<16:42, 66.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 346/360 [5:59:43<15:15, 65.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 347/360 [6:01:11<15:41, 72.39s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 348/360 [6:02:03<13:12, 66.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 349/360 [6:03:18<12:37, 68.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 350/360 [6:04:42<12:13, 73.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 351/360 [6:05:24<09:36, 64.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 352/360 [6:06:09<07:47, 58.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 353/360 [6:07:05<06:43, 57.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 354/360 [6:08:09<05:57, 59.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 355/360 [6:09:23<05:19, 63.89s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 356/360 [6:10:20<04:06, 61.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 357/360 [6:11:10<02:54, 58.25s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 358/360 [6:12:35<02:12, 66.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 359/360 [6:14:26<01:19, 79.57s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [6:16:01<00:00, 84.36s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Processing images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [6:16:01<00:00, 62.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY FOR QWEN2.5-VL\n",
      "============================================================\n",
      "ðŸ“Š IMAGE PROCESSING SUMMARY:\n",
      "   Total images attempted: 360\n",
      "   Successfully processed: 309 (85.8%)\n",
      "   Failed images: 51 (14.2%)\n",
      "\n",
      "ðŸ“ QUESTION PROCESSING SUMMARY:\n",
      "   Total questions attempted: 1080\n",
      "   Successfully processed: 927 (85.8%)\n",
      "   Failed questions: 153 (14.2%)\n",
      "   Results saved: 927\n",
      "\n",
      "âœ… SUCCESSFUL IMAGES (309):\n",
      "   â€¢ image01 (Type: REAL, Questions: 3/3, Time: 66.8s)\n",
      "   â€¢ image02 (Type: REAL, Questions: 3/3, Time: 82.8s)\n",
      "   â€¢ image03 (Type: REAL, Questions: 3/3, Time: 71.5s)\n",
      "   â€¢ image04 (Type: REAL, Questions: 3/3, Time: 84.5s)\n",
      "   â€¢ image05 (Type: REAL, Questions: 3/3, Time: 85.8s)\n",
      "   â€¢ image06 (Type: REAL, Questions: 3/3, Time: 111.7s)\n",
      "   â€¢ image07 (Type: REAL, Questions: 3/3, Time: 44.4s)\n",
      "   â€¢ image08 (Type: REAL, Questions: 3/3, Time: 31.9s)\n",
      "   â€¢ image09 (Type: REAL, Questions: 3/3, Time: 78.3s)\n",
      "   â€¢ image10 (Type: REAL, Questions: 3/3, Time: 110.7s)\n",
      "   â€¢ image11 (Type: REAL, Questions: 3/3, Time: 49.9s)\n",
      "   â€¢ image12 (Type: REAL, Questions: 3/3, Time: 110.3s)\n",
      "   â€¢ image13 (Type: REAL, Questions: 3/3, Time: 63.5s)\n",
      "   â€¢ image14 (Type: REAL, Questions: 3/3, Time: 29.2s)\n",
      "   â€¢ image15 (Type: REAL, Questions: 3/3, Time: 88.6s)\n",
      "   â€¢ image16 (Type: REAL, Questions: 3/3, Time: 94.2s)\n",
      "   â€¢ image17 (Type: REAL, Questions: 3/3, Time: 56.7s)\n",
      "   â€¢ image18 (Type: REAL, Questions: 3/3, Time: 65.9s)\n",
      "   â€¢ image19 (Type: REAL, Questions: 3/3, Time: 86.8s)\n",
      "   â€¢ image20 (Type: REAL, Questions: 3/3, Time: 58.0s)\n",
      "   â€¢ image21 (Type: REAL, Questions: 3/3, Time: 90.6s)\n",
      "   â€¢ image24 (Type: REAL, Questions: 3/3, Time: 77.3s)\n",
      "   â€¢ image25 (Type: REAL, Questions: 3/3, Time: 55.1s)\n",
      "   â€¢ image26 (Type: REAL, Questions: 3/3, Time: 93.1s)\n",
      "   â€¢ image27 (Type: REAL, Questions: 3/3, Time: 48.7s)\n",
      "   â€¢ image28 (Type: REAL, Questions: 3/3, Time: 65.7s)\n",
      "   â€¢ image29 (Type: REAL, Questions: 3/3, Time: 91.8s)\n",
      "   â€¢ image30 (Type: REAL, Questions: 3/3, Time: 65.9s)\n",
      "   â€¢ image31 (Type: REAL, Questions: 3/3, Time: 83.6s)\n",
      "   â€¢ image32 (Type: REAL, Questions: 3/3, Time: 79.0s)\n",
      "   â€¢ image33 (Type: REAL, Questions: 3/3, Time: 53.1s)\n",
      "   â€¢ image34 (Type: REAL, Questions: 3/3, Time: 63.3s)\n",
      "   â€¢ image35 (Type: REAL, Questions: 3/3, Time: 167.0s)\n",
      "   â€¢ image36 (Type: REAL, Questions: 3/3, Time: 135.5s)\n",
      "   â€¢ image37 (Type: REAL, Questions: 3/3, Time: 80.9s)\n",
      "   â€¢ image38 (Type: REAL, Questions: 3/3, Time: 58.8s)\n",
      "   â€¢ image39 (Type: REAL, Questions: 3/3, Time: 64.5s)\n",
      "   â€¢ image40 (Type: REAL, Questions: 3/3, Time: 85.6s)\n",
      "   â€¢ image41 (Type: REAL, Questions: 3/3, Time: 44.0s)\n",
      "   â€¢ image42 (Type: REAL, Questions: 3/3, Time: 42.3s)\n",
      "   â€¢ image43 (Type: REAL, Questions: 3/3, Time: 56.0s)\n",
      "   â€¢ image44 (Type: REAL, Questions: 3/3, Time: 73.0s)\n",
      "   â€¢ image45 (Type: REAL, Questions: 3/3, Time: 118.6s)\n",
      "   â€¢ image46 (Type: REAL, Questions: 3/3, Time: 126.3s)\n",
      "   â€¢ image47 (Type: REAL, Questions: 3/3, Time: 57.1s)\n",
      "   â€¢ image48 (Type: REAL, Questions: 3/3, Time: 47.5s)\n",
      "   â€¢ image49 (Type: REAL, Questions: 3/3, Time: 67.4s)\n",
      "   â€¢ image50 (Type: REAL, Questions: 3/3, Time: 71.2s)\n",
      "   â€¢ image51 (Type: REAL, Questions: 3/3, Time: 113.8s)\n",
      "   â€¢ image52 (Type: REAL, Questions: 3/3, Time: 52.5s)\n",
      "   â€¢ image53 (Type: REAL, Questions: 3/3, Time: 68.4s)\n",
      "   â€¢ image55 (Type: REAL, Questions: 3/3, Time: 53.2s)\n",
      "   â€¢ image57 (Type: REAL, Questions: 3/3, Time: 105.9s)\n",
      "   â€¢ image58 (Type: REAL, Questions: 3/3, Time: 60.4s)\n",
      "   â€¢ image59 (Type: REAL, Questions: 3/3, Time: 56.2s)\n",
      "   â€¢ image60 (Type: REAL, Questions: 3/3, Time: 102.8s)\n",
      "   â€¢ image61 (Type: REAL, Questions: 3/3, Time: 76.4s)\n",
      "   â€¢ image62 (Type: REAL, Questions: 3/3, Time: 45.8s)\n",
      "   â€¢ image63 (Type: REAL, Questions: 3/3, Time: 88.0s)\n",
      "   â€¢ image65 (Type: REAL, Questions: 3/3, Time: 64.4s)\n",
      "   â€¢ image66 (Type: REAL, Questions: 3/3, Time: 47.7s)\n",
      "   â€¢ image67 (Type: REAL, Questions: 3/3, Time: 76.8s)\n",
      "   â€¢ image68 (Type: REAL, Questions: 3/3, Time: 78.4s)\n",
      "   â€¢ image69 (Type: REAL, Questions: 3/3, Time: 101.3s)\n",
      "   â€¢ image70 (Type: REAL, Questions: 3/3, Time: 60.4s)\n",
      "   â€¢ image72 (Type: REAL, Questions: 3/3, Time: 60.4s)\n",
      "   â€¢ image73 (Type: REAL, Questions: 3/3, Time: 40.6s)\n",
      "   â€¢ image74 (Type: REAL, Questions: 3/3, Time: 69.3s)\n",
      "   â€¢ image76 (Type: REAL, Questions: 3/3, Time: 62.4s)\n",
      "   â€¢ image77 (Type: REAL, Questions: 3/3, Time: 38.8s)\n",
      "   â€¢ image78 (Type: REAL, Questions: 3/3, Time: 103.8s)\n",
      "   â€¢ image79 (Type: REAL, Questions: 3/3, Time: 114.4s)\n",
      "   â€¢ image80 (Type: REAL, Questions: 3/3, Time: 58.1s)\n",
      "   â€¢ image81 (Type: REAL, Questions: 3/3, Time: 42.2s)\n",
      "   â€¢ image82 (Type: REAL, Questions: 3/3, Time: 66.7s)\n",
      "   â€¢ image83 (Type: REAL, Questions: 3/3, Time: 58.3s)\n",
      "   â€¢ image86 (Type: REAL, Questions: 3/3, Time: 46.7s)\n",
      "   â€¢ image87 (Type: REAL, Questions: 3/3, Time: 82.1s)\n",
      "   â€¢ image88 (Type: REAL, Questions: 3/3, Time: 73.5s)\n",
      "   â€¢ image91 (Type: REAL, Questions: 3/3, Time: 106.5s)\n",
      "   â€¢ image93 (Type: REAL, Questions: 3/3, Time: 58.5s)\n",
      "   â€¢ image94 (Type: REAL, Questions: 3/3, Time: 64.0s)\n",
      "   â€¢ image95 (Type: REAL, Questions: 3/3, Time: 54.9s)\n",
      "   â€¢ image96 (Type: REAL, Questions: 3/3, Time: 86.7s)\n",
      "   â€¢ image98 (Type: REAL, Questions: 3/3, Time: 74.7s)\n",
      "   â€¢ image100 (Type: REAL, Questions: 3/3, Time: 96.7s)\n",
      "   â€¢ image101 (Type: REAL, Questions: 3/3, Time: 110.6s)\n",
      "   â€¢ image102 (Type: REAL, Questions: 3/3, Time: 77.4s)\n",
      "   â€¢ image103 (Type: REAL, Questions: 3/3, Time: 85.6s)\n",
      "   â€¢ image104 (Type: REAL, Questions: 3/3, Time: 74.8s)\n",
      "   â€¢ image105 (Type: REAL, Questions: 3/3, Time: 87.6s)\n",
      "   â€¢ image106 (Type: REAL, Questions: 3/3, Time: 100.0s)\n",
      "   â€¢ image107 (Type: REAL, Questions: 3/3, Time: 83.8s)\n",
      "   â€¢ image112 (Type: REAL, Questions: 3/3, Time: 106.7s)\n",
      "   â€¢ image113 (Type: REAL, Questions: 3/3, Time: 133.0s)\n",
      "   â€¢ image114 (Type: REAL, Questions: 3/3, Time: 119.5s)\n",
      "   â€¢ image115 (Type: REAL, Questions: 3/3, Time: 74.7s)\n",
      "   â€¢ image117 (Type: REAL, Questions: 3/3, Time: 68.6s)\n",
      "   â€¢ image118 (Type: REAL, Questions: 3/3, Time: 119.9s)\n",
      "   â€¢ image119 (Type: REAL, Questions: 3/3, Time: 75.7s)\n",
      "   â€¢ image120 (Type: REAL, Questions: 3/3, Time: 117.8s)\n",
      "   â€¢ image01 (Type: ANIMATED, Questions: 3/3, Time: 67.9s)\n",
      "   â€¢ image02 (Type: ANIMATED, Questions: 3/3, Time: 62.5s)\n",
      "   â€¢ image03 (Type: ANIMATED, Questions: 3/3, Time: 42.8s)\n",
      "   â€¢ image04 (Type: ANIMATED, Questions: 3/3, Time: 74.8s)\n",
      "   â€¢ image05 (Type: ANIMATED, Questions: 3/3, Time: 69.4s)\n",
      "   â€¢ image06 (Type: ANIMATED, Questions: 3/3, Time: 55.4s)\n",
      "   â€¢ image07 (Type: ANIMATED, Questions: 3/3, Time: 39.3s)\n",
      "   â€¢ image08 (Type: ANIMATED, Questions: 3/3, Time: 55.8s)\n",
      "   â€¢ image09 (Type: ANIMATED, Questions: 3/3, Time: 90.5s)\n",
      "   â€¢ image11 (Type: ANIMATED, Questions: 3/3, Time: 97.7s)\n",
      "   â€¢ image12 (Type: ANIMATED, Questions: 3/3, Time: 147.6s)\n",
      "   â€¢ image14 (Type: ANIMATED, Questions: 3/3, Time: 74.2s)\n",
      "   â€¢ image17 (Type: ANIMATED, Questions: 3/3, Time: 75.6s)\n",
      "   â€¢ image18 (Type: ANIMATED, Questions: 3/3, Time: 61.7s)\n",
      "   â€¢ image19 (Type: ANIMATED, Questions: 3/3, Time: 111.4s)\n",
      "   â€¢ image20 (Type: ANIMATED, Questions: 3/3, Time: 69.3s)\n",
      "   â€¢ image22 (Type: ANIMATED, Questions: 3/3, Time: 93.6s)\n",
      "   â€¢ image24 (Type: ANIMATED, Questions: 3/3, Time: 52.7s)\n",
      "   â€¢ image25 (Type: ANIMATED, Questions: 3/3, Time: 57.0s)\n",
      "   â€¢ image26 (Type: ANIMATED, Questions: 3/3, Time: 84.2s)\n",
      "   â€¢ image27 (Type: ANIMATED, Questions: 3/3, Time: 78.8s)\n",
      "   â€¢ image28 (Type: ANIMATED, Questions: 3/3, Time: 114.6s)\n",
      "   â€¢ image29 (Type: ANIMATED, Questions: 3/3, Time: 62.2s)\n",
      "   â€¢ image30 (Type: ANIMATED, Questions: 3/3, Time: 43.3s)\n",
      "   â€¢ image31 (Type: ANIMATED, Questions: 3/3, Time: 80.6s)\n",
      "   â€¢ image32 (Type: ANIMATED, Questions: 3/3, Time: 29.6s)\n",
      "   â€¢ image33 (Type: ANIMATED, Questions: 3/3, Time: 35.2s)\n",
      "   â€¢ image34 (Type: ANIMATED, Questions: 3/3, Time: 40.7s)\n",
      "   â€¢ image35 (Type: ANIMATED, Questions: 3/3, Time: 71.5s)\n",
      "   â€¢ image36 (Type: ANIMATED, Questions: 3/3, Time: 62.4s)\n",
      "   â€¢ image37 (Type: ANIMATED, Questions: 3/3, Time: 67.6s)\n",
      "   â€¢ image38 (Type: ANIMATED, Questions: 3/3, Time: 77.7s)\n",
      "   â€¢ image39 (Type: ANIMATED, Questions: 3/3, Time: 72.8s)\n",
      "   â€¢ image40 (Type: ANIMATED, Questions: 3/3, Time: 50.9s)\n",
      "   â€¢ image50 (Type: ANIMATED, Questions: 3/3, Time: 95.3s)\n",
      "   â€¢ image54 (Type: ANIMATED, Questions: 3/3, Time: 63.6s)\n",
      "   â€¢ image55 (Type: ANIMATED, Questions: 3/3, Time: 37.3s)\n",
      "   â€¢ image56 (Type: ANIMATED, Questions: 3/3, Time: 32.0s)\n",
      "   â€¢ image57 (Type: ANIMATED, Questions: 3/3, Time: 32.1s)\n",
      "   â€¢ image60 (Type: ANIMATED, Questions: 3/3, Time: 42.8s)\n",
      "   â€¢ image61 (Type: ANIMATED, Questions: 3/3, Time: 33.7s)\n",
      "   â€¢ image62 (Type: ANIMATED, Questions: 3/3, Time: 96.7s)\n",
      "   â€¢ image63 (Type: ANIMATED, Questions: 3/3, Time: 108.3s)\n",
      "   â€¢ image64 (Type: ANIMATED, Questions: 3/3, Time: 44.3s)\n",
      "   â€¢ image65 (Type: ANIMATED, Questions: 3/3, Time: 59.2s)\n",
      "   â€¢ image66 (Type: ANIMATED, Questions: 3/3, Time: 43.8s)\n",
      "   â€¢ image67 (Type: ANIMATED, Questions: 3/3, Time: 50.9s)\n",
      "   â€¢ image68 (Type: ANIMATED, Questions: 3/3, Time: 66.5s)\n",
      "   â€¢ image69 (Type: ANIMATED, Questions: 3/3, Time: 75.1s)\n",
      "   â€¢ image70 (Type: ANIMATED, Questions: 3/3, Time: 41.9s)\n",
      "   â€¢ image71 (Type: ANIMATED, Questions: 3/3, Time: 45.2s)\n",
      "   â€¢ image72 (Type: ANIMATED, Questions: 3/3, Time: 82.7s)\n",
      "   â€¢ image73 (Type: ANIMATED, Questions: 3/3, Time: 73.3s)\n",
      "   â€¢ image74 (Type: ANIMATED, Questions: 3/3, Time: 50.0s)\n",
      "   â€¢ image75 (Type: ANIMATED, Questions: 3/3, Time: 57.2s)\n",
      "   â€¢ image76 (Type: ANIMATED, Questions: 3/3, Time: 90.7s)\n",
      "   â€¢ image77 (Type: ANIMATED, Questions: 3/3, Time: 98.6s)\n",
      "   â€¢ image78 (Type: ANIMATED, Questions: 3/3, Time: 69.2s)\n",
      "   â€¢ image79 (Type: ANIMATED, Questions: 3/3, Time: 55.0s)\n",
      "   â€¢ image80 (Type: ANIMATED, Questions: 3/3, Time: 106.5s)\n",
      "   â€¢ image81 (Type: ANIMATED, Questions: 3/3, Time: 78.7s)\n",
      "   â€¢ image82 (Type: ANIMATED, Questions: 3/3, Time: 55.0s)\n",
      "   â€¢ image83 (Type: ANIMATED, Questions: 3/3, Time: 51.2s)\n",
      "   â€¢ image85 (Type: ANIMATED, Questions: 3/3, Time: 36.1s)\n",
      "   â€¢ image86 (Type: ANIMATED, Questions: 3/3, Time: 57.0s)\n",
      "   â€¢ image87 (Type: ANIMATED, Questions: 3/3, Time: 55.9s)\n",
      "   â€¢ image88 (Type: ANIMATED, Questions: 3/3, Time: 52.1s)\n",
      "   â€¢ image89 (Type: ANIMATED, Questions: 3/3, Time: 49.7s)\n",
      "   â€¢ image90 (Type: ANIMATED, Questions: 3/3, Time: 32.2s)\n",
      "   â€¢ image91 (Type: ANIMATED, Questions: 3/3, Time: 59.2s)\n",
      "   â€¢ image92 (Type: ANIMATED, Questions: 3/3, Time: 71.7s)\n",
      "   â€¢ image93 (Type: ANIMATED, Questions: 3/3, Time: 78.9s)\n",
      "   â€¢ image94 (Type: ANIMATED, Questions: 3/3, Time: 55.6s)\n",
      "   â€¢ image95 (Type: ANIMATED, Questions: 3/3, Time: 39.4s)\n",
      "   â€¢ image96 (Type: ANIMATED, Questions: 3/3, Time: 54.3s)\n",
      "   â€¢ image97 (Type: ANIMATED, Questions: 3/3, Time: 46.2s)\n",
      "   â€¢ image98 (Type: ANIMATED, Questions: 3/3, Time: 44.5s)\n",
      "   â€¢ image99 (Type: ANIMATED, Questions: 3/3, Time: 66.0s)\n",
      "   â€¢ image100 (Type: ANIMATED, Questions: 3/3, Time: 46.5s)\n",
      "   â€¢ image101 (Type: ANIMATED, Questions: 3/3, Time: 36.1s)\n",
      "   â€¢ image102 (Type: ANIMATED, Questions: 3/3, Time: 81.6s)\n",
      "   â€¢ image103 (Type: ANIMATED, Questions: 3/3, Time: 93.9s)\n",
      "   â€¢ image104 (Type: ANIMATED, Questions: 3/3, Time: 51.8s)\n",
      "   â€¢ image105 (Type: ANIMATED, Questions: 3/3, Time: 57.3s)\n",
      "   â€¢ image106 (Type: ANIMATED, Questions: 3/3, Time: 98.1s)\n",
      "   â€¢ image107 (Type: ANIMATED, Questions: 3/3, Time: 42.6s)\n",
      "   â€¢ image108 (Type: ANIMATED, Questions: 3/3, Time: 26.3s)\n",
      "   â€¢ image109 (Type: ANIMATED, Questions: 3/3, Time: 61.4s)\n",
      "   â€¢ image01 (Type: AI_GENERATED, Questions: 3/3, Time: 59.6s)\n",
      "   â€¢ image02 (Type: AI_GENERATED, Questions: 3/3, Time: 59.0s)\n",
      "   â€¢ image03 (Type: AI_GENERATED, Questions: 3/3, Time: 69.8s)\n",
      "   â€¢ image04 (Type: AI_GENERATED, Questions: 3/3, Time: 83.5s)\n",
      "   â€¢ image05 (Type: AI_GENERATED, Questions: 3/3, Time: 77.4s)\n",
      "   â€¢ image06 (Type: AI_GENERATED, Questions: 3/3, Time: 72.0s)\n",
      "   â€¢ image07 (Type: AI_GENERATED, Questions: 3/3, Time: 56.3s)\n",
      "   â€¢ image08 (Type: AI_GENERATED, Questions: 3/3, Time: 113.7s)\n",
      "   â€¢ image09 (Type: AI_GENERATED, Questions: 3/3, Time: 55.9s)\n",
      "   â€¢ image10 (Type: AI_GENERATED, Questions: 3/3, Time: 86.7s)\n",
      "   â€¢ image11 (Type: AI_GENERATED, Questions: 3/3, Time: 100.8s)\n",
      "   â€¢ image12 (Type: AI_GENERATED, Questions: 3/3, Time: 44.3s)\n",
      "   â€¢ image13 (Type: AI_GENERATED, Questions: 3/3, Time: 56.2s)\n",
      "   â€¢ image14 (Type: AI_GENERATED, Questions: 3/3, Time: 48.1s)\n",
      "   â€¢ image15 (Type: AI_GENERATED, Questions: 3/3, Time: 90.0s)\n",
      "   â€¢ image16 (Type: AI_GENERATED, Questions: 3/3, Time: 72.0s)\n",
      "   â€¢ image17 (Type: AI_GENERATED, Questions: 3/3, Time: 52.2s)\n",
      "   â€¢ image18 (Type: AI_GENERATED, Questions: 3/3, Time: 126.2s)\n",
      "   â€¢ image19 (Type: AI_GENERATED, Questions: 3/3, Time: 78.8s)\n",
      "   â€¢ image20 (Type: AI_GENERATED, Questions: 3/3, Time: 60.6s)\n",
      "   â€¢ image21 (Type: AI_GENERATED, Questions: 3/3, Time: 40.9s)\n",
      "   â€¢ image22 (Type: AI_GENERATED, Questions: 3/3, Time: 73.3s)\n",
      "   â€¢ image23 (Type: AI_GENERATED, Questions: 3/3, Time: 70.2s)\n",
      "   â€¢ image24 (Type: AI_GENERATED, Questions: 3/3, Time: 73.4s)\n",
      "   â€¢ image25 (Type: AI_GENERATED, Questions: 3/3, Time: 49.8s)\n",
      "   â€¢ image26 (Type: AI_GENERATED, Questions: 3/3, Time: 68.9s)\n",
      "   â€¢ image27 (Type: AI_GENERATED, Questions: 3/3, Time: 58.2s)\n",
      "   â€¢ image28 (Type: AI_GENERATED, Questions: 3/3, Time: 48.0s)\n",
      "   â€¢ image29 (Type: AI_GENERATED, Questions: 3/3, Time: 36.1s)\n",
      "   â€¢ image30 (Type: AI_GENERATED, Questions: 3/3, Time: 63.0s)\n",
      "   â€¢ image31 (Type: AI_GENERATED, Questions: 3/3, Time: 72.1s)\n",
      "   â€¢ image32 (Type: AI_GENERATED, Questions: 3/3, Time: 52.2s)\n",
      "   â€¢ image33 (Type: AI_GENERATED, Questions: 3/3, Time: 66.2s)\n",
      "   â€¢ image34 (Type: AI_GENERATED, Questions: 3/3, Time: 98.5s)\n",
      "   â€¢ image35 (Type: AI_GENERATED, Questions: 3/3, Time: 72.5s)\n",
      "   â€¢ image36 (Type: AI_GENERATED, Questions: 3/3, Time: 73.4s)\n",
      "   â€¢ image37 (Type: AI_GENERATED, Questions: 3/3, Time: 44.5s)\n",
      "   â€¢ image38 (Type: AI_GENERATED, Questions: 3/3, Time: 59.0s)\n",
      "   â€¢ image39 (Type: AI_GENERATED, Questions: 3/3, Time: 53.0s)\n",
      "   â€¢ image40 (Type: AI_GENERATED, Questions: 3/3, Time: 62.4s)\n",
      "   â€¢ image41 (Type: AI_GENERATED, Questions: 3/3, Time: 62.6s)\n",
      "   â€¢ image42 (Type: AI_GENERATED, Questions: 3/3, Time: 73.4s)\n",
      "   â€¢ image43 (Type: AI_GENERATED, Questions: 3/3, Time: 70.9s)\n",
      "   â€¢ image44 (Type: AI_GENERATED, Questions: 3/3, Time: 79.9s)\n",
      "   â€¢ image45 (Type: AI_GENERATED, Questions: 3/3, Time: 55.3s)\n",
      "   â€¢ image46 (Type: AI_GENERATED, Questions: 3/3, Time: 113.1s)\n",
      "   â€¢ image47 (Type: AI_GENERATED, Questions: 3/3, Time: 62.5s)\n",
      "   â€¢ image48 (Type: AI_GENERATED, Questions: 3/3, Time: 86.0s)\n",
      "   â€¢ image49 (Type: AI_GENERATED, Questions: 3/3, Time: 79.6s)\n",
      "   â€¢ image50 (Type: AI_GENERATED, Questions: 3/3, Time: 107.5s)\n",
      "   â€¢ image51 (Type: AI_GENERATED, Questions: 3/3, Time: 101.1s)\n",
      "   â€¢ image52 (Type: AI_GENERATED, Questions: 3/3, Time: 129.7s)\n",
      "   â€¢ image53 (Type: AI_GENERATED, Questions: 3/3, Time: 99.5s)\n",
      "   â€¢ image54 (Type: AI_GENERATED, Questions: 3/3, Time: 143.7s)\n",
      "   â€¢ image55 (Type: AI_GENERATED, Questions: 3/3, Time: 88.6s)\n",
      "   â€¢ image56 (Type: AI_GENERATED, Questions: 3/3, Time: 52.6s)\n",
      "   â€¢ image57 (Type: AI_GENERATED, Questions: 3/3, Time: 63.7s)\n",
      "   â€¢ image58 (Type: AI_GENERATED, Questions: 3/3, Time: 136.0s)\n",
      "   â€¢ image59 (Type: AI_GENERATED, Questions: 3/3, Time: 66.7s)\n",
      "   â€¢ image60 (Type: AI_GENERATED, Questions: 3/3, Time: 80.8s)\n",
      "   â€¢ image61 (Type: AI_GENERATED, Questions: 3/3, Time: 100.5s)\n",
      "   â€¢ image62 (Type: AI_GENERATED, Questions: 3/3, Time: 136.5s)\n",
      "   â€¢ image63 (Type: AI_GENERATED, Questions: 3/3, Time: 92.1s)\n",
      "   â€¢ image64 (Type: AI_GENERATED, Questions: 3/3, Time: 68.8s)\n",
      "   â€¢ image65 (Type: AI_GENERATED, Questions: 3/3, Time: 65.4s)\n",
      "   â€¢ image66 (Type: AI_GENERATED, Questions: 3/3, Time: 83.7s)\n",
      "   â€¢ image67 (Type: AI_GENERATED, Questions: 3/3, Time: 78.2s)\n",
      "   â€¢ image68 (Type: AI_GENERATED, Questions: 3/3, Time: 72.5s)\n",
      "   â€¢ image69 (Type: AI_GENERATED, Questions: 3/3, Time: 101.9s)\n",
      "   â€¢ image70 (Type: AI_GENERATED, Questions: 3/3, Time: 126.8s)\n",
      "   â€¢ image71 (Type: AI_GENERATED, Questions: 3/3, Time: 40.9s)\n",
      "   â€¢ image72 (Type: AI_GENERATED, Questions: 3/3, Time: 46.3s)\n",
      "   â€¢ image73 (Type: AI_GENERATED, Questions: 3/3, Time: 104.0s)\n",
      "   â€¢ image74 (Type: AI_GENERATED, Questions: 3/3, Time: 48.0s)\n",
      "   â€¢ image75 (Type: AI_GENERATED, Questions: 3/3, Time: 44.5s)\n",
      "   â€¢ image76 (Type: AI_GENERATED, Questions: 3/3, Time: 39.1s)\n",
      "   â€¢ image77 (Type: AI_GENERATED, Questions: 3/3, Time: 114.1s)\n",
      "   â€¢ image78 (Type: AI_GENERATED, Questions: 3/3, Time: 82.1s)\n",
      "   â€¢ image79 (Type: AI_GENERATED, Questions: 3/3, Time: 67.2s)\n",
      "   â€¢ image80 (Type: AI_GENERATED, Questions: 3/3, Time: 103.2s)\n",
      "   â€¢ image81 (Type: AI_GENERATED, Questions: 3/3, Time: 64.4s)\n",
      "   â€¢ image82 (Type: AI_GENERATED, Questions: 3/3, Time: 60.4s)\n",
      "   â€¢ image83 (Type: AI_GENERATED, Questions: 3/3, Time: 74.7s)\n",
      "   â€¢ image84 (Type: AI_GENERATED, Questions: 3/3, Time: 91.1s)\n",
      "   â€¢ image85 (Type: AI_GENERATED, Questions: 3/3, Time: 36.5s)\n",
      "   â€¢ image86 (Type: AI_GENERATED, Questions: 3/3, Time: 67.2s)\n",
      "   â€¢ image87 (Type: AI_GENERATED, Questions: 3/3, Time: 69.0s)\n",
      "   â€¢ image88 (Type: AI_GENERATED, Questions: 3/3, Time: 51.5s)\n",
      "   â€¢ image89 (Type: AI_GENERATED, Questions: 3/3, Time: 45.9s)\n",
      "   â€¢ image90 (Type: AI_GENERATED, Questions: 3/3, Time: 78.5s)\n",
      "   â€¢ image91 (Type: AI_GENERATED, Questions: 3/3, Time: 70.5s)\n",
      "   â€¢ image92 (Type: AI_GENERATED, Questions: 3/3, Time: 67.8s)\n",
      "   â€¢ image93 (Type: AI_GENERATED, Questions: 3/3, Time: 55.9s)\n",
      "   â€¢ image94 (Type: AI_GENERATED, Questions: 3/3, Time: 83.6s)\n",
      "   â€¢ image95 (Type: AI_GENERATED, Questions: 3/3, Time: 90.9s)\n",
      "   â€¢ image96 (Type: AI_GENERATED, Questions: 3/3, Time: 67.0s)\n",
      "   â€¢ image97 (Type: AI_GENERATED, Questions: 3/3, Time: 69.7s)\n",
      "   â€¢ image98 (Type: AI_GENERATED, Questions: 3/3, Time: 72.3s)\n",
      "   â€¢ image99 (Type: AI_GENERATED, Questions: 3/3, Time: 89.5s)\n",
      "   â€¢ image100 (Type: AI_GENERATED, Questions: 3/3, Time: 84.9s)\n",
      "   â€¢ image101 (Type: AI_GENERATED, Questions: 3/3, Time: 88.8s)\n",
      "   â€¢ image102 (Type: AI_GENERATED, Questions: 3/3, Time: 64.0s)\n",
      "   â€¢ image103 (Type: AI_GENERATED, Questions: 3/3, Time: 52.5s)\n",
      "   â€¢ image104 (Type: AI_GENERATED, Questions: 3/3, Time: 80.5s)\n",
      "   â€¢ image105 (Type: AI_GENERATED, Questions: 3/3, Time: 52.7s)\n",
      "   â€¢ image106 (Type: AI_GENERATED, Questions: 3/3, Time: 62.0s)\n",
      "   â€¢ image107 (Type: AI_GENERATED, Questions: 3/3, Time: 88.7s)\n",
      "   â€¢ image108 (Type: AI_GENERATED, Questions: 3/3, Time: 51.3s)\n",
      "   â€¢ image109 (Type: AI_GENERATED, Questions: 3/3, Time: 75.5s)\n",
      "   â€¢ image110 (Type: AI_GENERATED, Questions: 3/3, Time: 83.8s)\n",
      "   â€¢ image111 (Type: AI_GENERATED, Questions: 3/3, Time: 42.4s)\n",
      "   â€¢ image112 (Type: AI_GENERATED, Questions: 3/3, Time: 45.1s)\n",
      "   â€¢ image113 (Type: AI_GENERATED, Questions: 3/3, Time: 55.8s)\n",
      "   â€¢ image114 (Type: AI_GENERATED, Questions: 3/3, Time: 63.9s)\n",
      "   â€¢ image115 (Type: AI_GENERATED, Questions: 3/3, Time: 74.1s)\n",
      "   â€¢ image116 (Type: AI_GENERATED, Questions: 3/3, Time: 56.7s)\n",
      "   â€¢ image117 (Type: AI_GENERATED, Questions: 3/3, Time: 50.1s)\n",
      "   â€¢ image118 (Type: AI_GENERATED, Questions: 3/3, Time: 85.2s)\n",
      "   â€¢ image119 (Type: AI_GENERATED, Questions: 3/3, Time: 110.4s)\n",
      "   â€¢ image120 (Type: AI_GENERATED, Questions: 3/3, Time: 95.5s)\n",
      "\n",
      "âŒ FAILED/PROBLEMATIC IMAGES (51):\n",
      "   â€¢ image22 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image23 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image54 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image56 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image64 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image71 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image75 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image84 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image85 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image89 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image90 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image92 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image97 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image99 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image108 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image109 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image110 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image111 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image116 (Type: REAL) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image10 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image13 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image15 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image16 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image21 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image23 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image41 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image42 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image43 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image44 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image45 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image46 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image47 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image48 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image49 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image51 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image52 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image53 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image58 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image59 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image84 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image110 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image111 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image112 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image113 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image114 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image115 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image116 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image117 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image118 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image119 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "   â€¢ image120 (Type: ANIMATED) - PARTIAL: 3/3 failed (0.0% success)\n",
      "\n",
      "ðŸ“ˆ FAILURE ANALYSIS BY IMAGE TYPE:\n",
      "   â€¢ REAL: 19 failed images\n",
      "     - image22 (partial_failure)\n",
      "     - image23 (partial_failure)\n",
      "     - image54 (partial_failure)\n",
      "     - image56 (partial_failure)\n",
      "     - image64 (partial_failure)\n",
      "     - image71 (partial_failure)\n",
      "     - image75 (partial_failure)\n",
      "     - image84 (partial_failure)\n",
      "     - image85 (partial_failure)\n",
      "     - image89 (partial_failure)\n",
      "     - image90 (partial_failure)\n",
      "     - image92 (partial_failure)\n",
      "     - image97 (partial_failure)\n",
      "     - image99 (partial_failure)\n",
      "     - image108 (partial_failure)\n",
      "     - image109 (partial_failure)\n",
      "     - image110 (partial_failure)\n",
      "     - image111 (partial_failure)\n",
      "     - image116 (partial_failure)\n",
      "   â€¢ ANIMATED: 32 failed images\n",
      "     - image10 (partial_failure)\n",
      "     - image13 (partial_failure)\n",
      "     - image15 (partial_failure)\n",
      "     - image16 (partial_failure)\n",
      "     - image21 (partial_failure)\n",
      "     - image23 (partial_failure)\n",
      "     - image41 (partial_failure)\n",
      "     - image42 (partial_failure)\n",
      "     - image43 (partial_failure)\n",
      "     - image44 (partial_failure)\n",
      "     - image45 (partial_failure)\n",
      "     - image46 (partial_failure)\n",
      "     - image47 (partial_failure)\n",
      "     - image48 (partial_failure)\n",
      "     - image49 (partial_failure)\n",
      "     - image51 (partial_failure)\n",
      "     - image52 (partial_failure)\n",
      "     - image53 (partial_failure)\n",
      "     - image58 (partial_failure)\n",
      "     - image59 (partial_failure)\n",
      "     - image84 (partial_failure)\n",
      "     - image110 (partial_failure)\n",
      "     - image111 (partial_failure)\n",
      "     - image112 (partial_failure)\n",
      "     - image113 (partial_failure)\n",
      "     - image114 (partial_failure)\n",
      "     - image115 (partial_failure)\n",
      "     - image116 (partial_failure)\n",
      "     - image117 (partial_failure)\n",
      "     - image118 (partial_failure)\n",
      "     - image119 (partial_failure)\n",
      "     - image120 (partial_failure)\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_Qwen2_5VL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac9336f",
   "metadata": {
    "papermill": {
     "duration": 0.03132,
     "end_time": "2025-07-28T20:21:14.655716",
     "exception": false,
     "start_time": "2025-07-28T20:21:14.624396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7163706,
     "sourceId": 11436696,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python ((op_bench)",
   "language": "python",
   "name": "op_bench"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22661.036525,
   "end_time": "2025-07-28T20:21:18.317604",
   "environment_variables": {},
   "exception": null,
   "input_path": "/var/scratch/ave303/OP_bench/opa-benchmark-smolvlm2-qwen2-5-vl.ipynb",
   "output_path": "qwen2-5-vl_32b_output.ipynb",
   "parameters": {},
   "start_time": "2025-07-28T14:03:37.281079",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
